{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eff6f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T11:42:33.483424Z",
     "iopub.status.busy": "2025-09-03T11:42:33.483170Z",
     "iopub.status.idle": "2025-09-03T11:42:48.630180Z",
     "shell.execute_reply": "2025-09-03T11:42:48.629355Z"
    },
    "papermill": {
     "duration": 15.152717,
     "end_time": "2025-09-03T11:42:48.631675",
     "exception": false,
     "start_time": "2025-09-03T11:42:33.478958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, joblib, numpy as np, pandas as pd\n",
    "import random, math\n",
    "from pathlib import Path\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from scipy.signal import firwin\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from functools import partial\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from types import SimpleNamespace\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e1111f",
   "metadata": {
    "_cell_guid": "a9a3a782-9671-4a0b-8dba-80f2fbadac12",
    "_uuid": "0d69a6d0-de36-4fd5-8bb7-78fe03c5324b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-03T11:42:48.638785Z",
     "iopub.status.busy": "2025-09-03T11:42:48.638397Z",
     "iopub.status.idle": "2025-09-03T11:42:48.718027Z",
     "shell.execute_reply": "2025-09-03T11:42:48.717269Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.084128,
     "end_time": "2025-09-03T11:42:48.719191",
     "exception": false,
     "start_time": "2025-09-03T11:42:48.635063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ imports ready · pytorch 2.6.0+cu124 · device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "TRAIN = False                     # ← set to True when you want to train\n",
    "RAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\n",
    "PRETRAINED_DIR = Path(\"/kaggle/input/cmi-1d-cnn-v2\") # used when TRAIN=False\n",
    "EXPORT_DIR = Path(\"./\")                                    # artefacts will be saved here\n",
    "BATCH_SIZE = 64\n",
    "PAD_PERCENTILE = 100\n",
    "maxlen = PAD_PERCENTILE\n",
    "LR_INIT = 1e-3\n",
    "WD = 3e-3\n",
    "MIXUP_ALPHA = 0.4\n",
    "MASKING_PROB = 0.25\n",
    "PATIENCE = 40\n",
    "FOLDS = 5\n",
    "random_state = 42\n",
    "epochs_warmup = 20\n",
    "warmup_lr_init = 1.822126131809773e-05\n",
    "lr_min = 3.810323058740104e-09\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"▶ imports ready · pytorch {torch.__version__} · device: {device}\")\n",
    "\n",
    "# ================================\n",
    "# Model Components\n",
    "# ================================\n",
    "\n",
    "class ImuFeatureExtractor(nn.Module):\n",
    "    def __init__(self, fs=10., add_quaternion=False):\n",
    "        super().__init__()\n",
    "        self.fs = fs\n",
    "        self.add_quaternion = add_quaternion\n",
    "\n",
    "        k = 15\n",
    "\n",
    "        self.lpf_acc   = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n",
    "        nn.init.kaiming_normal_(self.lpf_acc.weight, mode='fan_out')\n",
    "        self.lpf_gyro = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n",
    "        nn.init.kaiming_normal_(self.lpf_gyro.weight, mode='fan_out')\n",
    "\n",
    "\n",
    "    def forward(self, imu):\n",
    "        # imu: \n",
    "        B, C, T = imu.shape\n",
    "        acc  = imu[:, 0:3, :]                 # acc_x, acc_y, acc_z\n",
    "        gyro = imu[:, 4:7, :]                 # gyro_x, gyro_y, gyro_z\n",
    "        linear_acc      = imu[:, 7:10, :]\n",
    "        angular_vel     = imu[:, 10:13, :]\n",
    "        angular_distance = imu[:, 13:14, :] # 保持维度 (B, 1, T)    \n",
    " \n",
    "\n",
    "        # 线性加速度的幅度和jerk\n",
    "        linear_acc_mag = torch.norm(linear_acc, dim=1, keepdim=True)\n",
    "        linear_acc_mag_jerk = F.pad(linear_acc_mag[:, :, 1:] - linear_acc_mag[:, :, :-1], (1,0), 'replicate')  \n",
    "\n",
    "        angular_vel_mag = torch.norm(angular_vel, dim=1, keepdim=True)\n",
    "        angular_vel_mag_jerk = F.pad(angular_vel_mag[:, :, 1:] - angular_vel_mag[:, :, :-1], (1,0), 'replicate')  \n",
    "\n",
    "        rot_angle = 2 * torch.acos(imu[:, 3, :].clamp(-1.0, 1.0)).unsqueeze(1) # rot_w is the 4th comp\n",
    "        rot_angle_vel = F.pad(rot_angle[:, :, 1:] - rot_angle[:, :, :-1], (1,0), 'replicate')\n",
    "\n",
    "        # 1) magnitude\n",
    "        acc_mag  = torch.norm(acc,  dim=1, keepdim=True)          # (B,1,T)\n",
    "        gyro_mag = torch.norm(gyro, dim=1, keepdim=True)\n",
    "\n",
    "        # 2) jerk \n",
    "        jerk = F.pad(acc[:, :, 1:] - acc[:, :, :-1], (1,0))       # (B,3,T)\n",
    "        gyro_delta = F.pad(gyro[:, :, 1:] - gyro[:, :, :-1], (1,0))\n",
    "\n",
    "        # 3) energy\n",
    "        acc_pow  = acc ** 2\n",
    "        gyro_pow = gyro ** 2\n",
    "\n",
    "        # 4) LPF / HPF \n",
    "        acc_lpf  = self.lpf_acc(acc)\n",
    "        acc_hpf  = acc - acc_lpf\n",
    "        gyro_lpf = self.lpf_gyro(gyro)\n",
    "        gyro_hpf = gyro - gyro_lpf\n",
    "\n",
    "\n",
    "        acc_features = [\n",
    "            acc, acc_mag,\n",
    "            jerk, acc_pow,\n",
    "            acc_lpf, acc_hpf,\n",
    "            linear_acc, linear_acc_mag, linear_acc_mag_jerk\n",
    "        ]\n",
    "        gyro_features = [\n",
    "            gyro, gyro_mag,\n",
    "            gyro_delta, gyro_pow,\n",
    "            gyro_lpf, gyro_hpf,\n",
    "            angular_vel, angular_vel_mag, angular_vel_mag_jerk, angular_distance,\n",
    "            rot_angle, rot_angle_vel\n",
    "        ]\n",
    "        # print(torch.cat(acc_features, dim=1).shape, torch.cat(gyro_features, dim=1).shape)\n",
    "        features = acc_features + gyro_features\n",
    "        return torch.cat(features, dim=1)\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool1d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.squeeze(x).view(b, c)\n",
    "        y = self.excitation(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class ResidualSECNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, pool_size=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First conv block\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Second conv block\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # SE block\n",
    "        self.se = SEBlock(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(pool_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        \n",
    "        # First conv\n",
    "        out = F.silu(self.bn1(self.conv1(x)))\n",
    "        # Second conv\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        # SE block\n",
    "        out = self.se(out)\n",
    "        \n",
    "        # Add shortcut\n",
    "        out += shortcut\n",
    "        out = F.silu(out)\n",
    "        \n",
    "        # Pool and dropout\n",
    "        out = self.pool(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, hidden_dim)\n",
    "        scores = torch.tanh(self.attention(x))  # (batch, seq_len, 1)\n",
    "        weights = F.softmax(scores.squeeze(-1), dim=1)  # (batch, seq_len)\n",
    "        context = torch.sum(x * weights.unsqueeze(-1), dim=1)  # (batch, hidden_dim)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16875bb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T11:42:48.725554Z",
     "iopub.status.busy": "2025-09-03T11:42:48.725336Z",
     "iopub.status.idle": "2025-09-03T11:42:48.737909Z",
     "shell.execute_reply": "2025-09-03T11:42:48.737283Z"
    },
    "papermill": {
     "duration": 0.017087,
     "end_time": "2025-09-03T11:42:48.738909",
     "exception": false,
     "start_time": "2025-09-03T11:42:48.721822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TwoBranchModel(nn.Module):\n",
    "    def __init__(self, pad_len, imu_dim_raw, tof_dim, n_classes, dropouts=[0.3, 0.3, 0.3, 0.3, 0.4, 0.5, 0.3], \n",
    "                 feature_engineering=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.feature_engineering = feature_engineering\n",
    "        if feature_engineering:\n",
    "            self.imu_fe = ImuFeatureExtractor(**kwargs)\n",
    "            imu_dim = 45\n",
    "        else:\n",
    "            self.imu_fe = nn.Identity()\n",
    "            imu_dim = imu_dim_raw\n",
    "            \n",
    "        self.imu_dim = imu_dim\n",
    "        self.tof_dim = tof_dim\n",
    "        self.fir_nchan = imu_dim_raw\n",
    "        \n",
    "        # --- 1. 保留输入分支 (与原模型相同) ---\n",
    "        # IMU deep branch\n",
    "        # self.imu_block1 = ResidualSECNNBlock(imu_dim, 64, 3, 1, dropout=dropouts[0])\n",
    "        # self.imu_block2 = ResidualSECNNBlock(64, 128, 5, 1, dropout=dropouts[1])\n",
    "        self.acc_dim, self.rot_dim = 21, 24\n",
    "        self.imu_block11 = ResidualSECNNBlock(self.acc_dim, 64, 3, 1, dropout=dropouts[0])\n",
    "        self.imu_block12 = ResidualSECNNBlock(64, 128, 5, 1, dropout=dropouts[1])\n",
    "        self.imu_block21 = ResidualSECNNBlock(self.rot_dim, 64, 3, 1, dropout=dropouts[0])\n",
    "        self.imu_block22 = ResidualSECNNBlock(64, 128, 5, 1, dropout=dropouts[1])\n",
    "        \n",
    "        # TOF/Thermal lighter branch\n",
    "        # v1\n",
    "        # self.tof_conv1 = nn.Conv1d(tof_dim, 64, 3, padding=1, bias=False)\n",
    "        # self.tof_bn1 = nn.BatchNorm1d(64)\n",
    "        # self.tof_drop1 = nn.Dropout(dropouts[2])\n",
    "        \n",
    "        # self.tof_conv2 = nn.Conv1d(64, 128, 3, padding=1, bias=False)\n",
    "        # self.tof_bn2 = nn.BatchNorm1d(128)\n",
    "        # self.tof_drop2 = nn.Dropout(dropouts[3])\n",
    "\n",
    "        # v2\n",
    "        self.tof_conv1 = ResidualSECNNBlock(tof_dim, 64, 3, 1, dropout=dropouts[2])\n",
    "        self.tof_conv2 = ResidualSECNNBlock(64, 128, 3, 1, dropout=dropouts[3])\n",
    "\n",
    "    \n",
    "\n",
    "        # Gate\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dense1_gate = nn.Linear(pad_len, 16)\n",
    "        self.dense2_gate = nn.Linear(16, 1)\n",
    "\n",
    "        \n",
    "\n",
    "        merged_channels = 256 + 128\n",
    "        self.cnn_backbone1 = nn.Sequential(\n",
    "            nn.Conv1d(merged_channels, 256, kernel_size=7, padding=3, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropouts[4])\n",
    "        )\n",
    "        self.cnn_backbone2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=5, padding=2, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropouts[5])\n",
    "        )\n",
    "\n",
    "        \n",
    "        # --- 3. 新增全局池化层 ---\n",
    "        # 使用自适应平均池化将时间维度压缩为1\n",
    "        # self.global_pool = AttentionLayer(512)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  \n",
    "\n",
    "        # --- 4. 修改全连接层 ---\n",
    "        # 输入维度需要从原来的 atten_dim (528) 修改为最后一个CNN层的输出通道数 (512)\n",
    "        cnn_out_dim = 512\n",
    "        self.dense1 = nn.Linear(cnn_out_dim, 256, bias=False)\n",
    "        self.bn_dense1 = nn.BatchNorm1d(256)\n",
    "        self.drop1 = nn.Dropout(dropouts[5]) # 复用一个dropout值\n",
    "        \n",
    "        self.dense2 = nn.Linear(256, 128, bias=False)\n",
    "        self.bn_dense2 = nn.BatchNorm1d(128)\n",
    "        self.drop2 = nn.Dropout(dropouts[6])\n",
    "        \n",
    "        self.classifier = nn.Linear(128, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # --- 与原模型相同的部分 ---\n",
    "        # 分割输入\n",
    "        imu = x[:, :, :self.fir_nchan].transpose(1, 2)  # (B, D_imu_raw, T)\n",
    "        tof = x[:, :, self.fir_nchan:].transpose(1, 2)  # (B, D_tof, T)\n",
    "\n",
    "        imu = self.imu_fe(imu)  # (B, D_imu, T)\n",
    "        \n",
    "        \n",
    "        # IMU 分支\n",
    "        # x1 = self.imu_block1(imu) # (B, 64, T)\n",
    "        # x1 = self.imu_block2(x1) # (B, 128, T)\n",
    "        acc = imu[:, :self.acc_dim, :]  # 保留前21个通道作为加速度特征\n",
    "        rot = imu[:, self.acc_dim:, :]  \n",
    "        x11 = self.imu_block11(acc) # (B, 64, T)\n",
    "        x11 = self.imu_block12(x11) # (B, 64, T)\n",
    "        \n",
    "        x12 = self.imu_block21(rot) # (B, 64, T)\n",
    "        x12 = self.imu_block22(x12) # (B, 64, T)\n",
    "        x1 = torch.cat([x11, x12], dim=1)\n",
    "\n",
    "        \n",
    "        # TOF 分支\n",
    "        # v1\n",
    "        # x2 = F.silu(self.tof_bn1(self.tof_conv1(tof)))\n",
    "        # x2 = self.tof_drop1(x2) # (B, 64, T)\n",
    "        # x2 = F.silu(self.tof_bn2(self.tof_conv2(x2)))\n",
    "        # x2 = self.tof_drop2(x2) # (B, 128, T)\n",
    "        \n",
    "        # v2\n",
    "        x2 = self.tof_conv1(tof)\n",
    "        x2 = self.tof_conv2(x2)\n",
    "        \n",
    "\n",
    "        # Gate x2\n",
    "        gate_input = self.pool(tof.transpose(1, 2)).squeeze(-1)\n",
    "        gate_input = F.silu(self.dense1_gate(gate_input))\n",
    "    \n",
    "        gate = torch.sigmoid(self.dense2_gate(gate_input)) # -> (B, 1)\n",
    "        x2 = x2 * gate.unsqueeze(-1)\n",
    "        \n",
    "        # 合并分支, Conv1d期望的输入格式是 (Batch, Channels, Length)\n",
    "        # 所以我们不需要像RNN那样进行转置\n",
    "        merged = torch.cat([x1, x2], dim=1) # (B, 256, T)\n",
    "        \n",
    "        # --- 新的CNN处理流程 ---\n",
    "        # 通过CNN主干网络\n",
    "        cnn_out = self.cnn_backbone1(merged) # (B, 256, T)\n",
    "        cnn_out = self.cnn_backbone2(cnn_out) # (B, 512, T)\n",
    "\n",
    "        \n",
    "        # 全局池化\n",
    "        pooled = self.global_pool(cnn_out) # (B, 512, 1)\n",
    "        pooled_flat = torch.flatten(pooled, 1) # (B, 512)\n",
    "        # pooled_flat = self.global_pool(cnn_out.transpose(1, 2))\n",
    "        \n",
    "        # --- 全连接层分类 (与原模型类似) ---\n",
    "        x = F.silu(self.bn_dense1(self.dense1(pooled_flat)))\n",
    "        x = self.drop1(x)\n",
    "        x = F.silu(self.bn_dense2(self.dense2(x)))\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        logits = self.classifier(x)\n",
    "        return logits, x, gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408b0f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T11:42:48.744824Z",
     "iopub.status.busy": "2025-09-03T11:42:48.744574Z",
     "iopub.status.idle": "2025-09-03T11:42:48.757013Z",
     "shell.execute_reply": "2025-09-03T11:42:48.756429Z"
    },
    "papermill": {
     "duration": 0.016655,
     "end_time": "2025-09-03T11:42:48.757997",
     "exception": false,
     "start_time": "2025-09-03T11:42:48.741342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_gravity_from_acc(acc_data, rot_data):\n",
    "\n",
    "    if isinstance(acc_data, pd.DataFrame):\n",
    "        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n",
    "    else:\n",
    "        acc_values = acc_data\n",
    "\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = acc_values.shape[0]\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    \n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :] \n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "             linear_accel[i, :] = acc_values[i, :]\n",
    "             \n",
    "    return linear_accel\n",
    "\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "\n",
    "            # Calculate the relative rotation\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            \n",
    "            # Convert delta rotation to angular velocity vector\n",
    "            # The rotation vector (Euler axis * angle) scaled by 1/dt\n",
    "            # is a good approximation for small delta_rot\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            # If quaternion is invalid, angular velocity remains zero\n",
    "            pass\n",
    "            \n",
    "    return angular_vel\n",
    "\n",
    "def calculate_angular_distance(rot_data):\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n",
    "            continue\n",
    "        try:\n",
    "            # Преобразование кватернионов в объекты Rotation\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n",
    "            # где p* - сопряженный кватернион q\n",
    "            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n",
    "            # Угол этого относительного вращения - это и есть угловое расстояние.\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            \n",
    "            # Угол rotation vector соответствует угловому расстоянию\n",
    "            # Норма rotation vector - это угол в радианах\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0 # В случае недействительных кватернионов\n",
    "            pass\n",
    "            \n",
    "    return angular_dist\n",
    "\n",
    "def pad_sequences_torch(sequences, maxlen, padding='post', truncating='post', value=0.0):\n",
    "    \"\"\"PyTorch equivalent of Keras pad_sequences\"\"\"\n",
    "    result = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) >= maxlen:\n",
    "            if truncating == 'post':\n",
    "                seq = seq[:maxlen]\n",
    "            else:  # 'pre'\n",
    "                seq = seq[-maxlen:]\n",
    "        else:\n",
    "            pad_len = maxlen - len(seq)\n",
    "            if padding == 'post':\n",
    "                seq = np.concatenate([seq, np.full((pad_len, seq.shape[1]), value)])\n",
    "            else:  # 'pre'\n",
    "                seq = np.concatenate([np.full((pad_len, seq.shape[1]), value), seq])\n",
    "        result.append(seq)\n",
    "    return np.array(result, dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da271a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T11:42:48.764163Z",
     "iopub.status.busy": "2025-09-03T11:42:48.763931Z",
     "iopub.status.idle": "2025-09-03T11:42:49.686338Z",
     "shell.execute_reply": "2025-09-03T11:42:49.685551Z"
    },
    "papermill": {
     "duration": 0.926973,
     "end_time": "2025-09-03T11:42:49.687528",
     "exception": false,
     "start_time": "2025-09-03T11:42:48.760555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ INFERENCE MODE – loading artefacts from /kaggle/input/cmi-1d-cnn-v2\n",
      "  model, scaler, pads loaded – ready for evaluation\n"
     ]
    }
   ],
   "source": [
    "print(\"▶ INFERENCE MODE – loading artefacts from\", PRETRAINED_DIR)\n",
    "feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n",
    "pad_len = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n",
    "scaler = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n",
    "gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "imu_cols = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n",
    "tof_cols = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n",
    "\n",
    "\n",
    "# Load model\n",
    "MODELS = [f'gesture_two_branch_fold{i}.pth' for i in range(5)]\n",
    "\n",
    "models = []\n",
    "for path in MODELS:\n",
    "    checkpoint = torch.load(PRETRAINED_DIR / path, map_location=device)\n",
    "    \n",
    "    model = TwoBranchModel(\n",
    "        checkpoint['pad_len'], \n",
    "        checkpoint['imu_dim'], \n",
    "        checkpoint['tof_dim'], \n",
    "        checkpoint['n_classes']\n",
    "        ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "print(\"  model, scaler, pads loaded – ready for evaluation\")\n",
    "\n",
    "# Make sure gesture_classes exists in both modes\n",
    "if TRAIN:\n",
    "    gesture_classes = le.classes_\n",
    "\n",
    "# def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "#     \"\"\"Prediction function for Kaggle competition\"\"\"\n",
    "#     global gesture_classes\n",
    "#     if gesture_classes is None:\n",
    "#         gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "#     df_seq = sequence.to_pandas()\n",
    "#     df_demo = demographics.to_pandas()\n",
    "#     df_seq = df_seq.merge(df_demo[['subject', 'handedness']], on='subject', how='left')\n",
    "#     handedness = df_seq['handedness'].iloc[0]\n",
    "#     if handedness == 0:\n",
    "#         # --- a) Swap sensor 3 and sensor 5 data ---\n",
    "        \n",
    "#         # Find all columns related to thermopile and time-of-flight sensors 3 and 5\n",
    "#         cols_3 = [c for c in df_seq.columns if any(p in c for p in ['tof_3', 'thm_3'])]\n",
    "#         cols_5 = [c for c in df_seq.columns if any(p in c for p in ['tof_5', 'thm_5'])]\n",
    "        \n",
    "#         # Sort to ensure a one-to-one mapping for the swap\n",
    "#         cols_3.sort()\n",
    "#         cols_5.sort()\n",
    "        \n",
    "#         # Sanity check\n",
    "#         if len(cols_3) == len(cols_5):\n",
    "#             # Perform the swap using a temporary variable\n",
    "#             temp_cols_3_data = df_seq[cols_3].copy()\n",
    "#             df_seq[cols_3] = df_seq[cols_5]\n",
    "#             df_seq[cols_5] = temp_cols_3_data\n",
    "        \n",
    "#         # --- b) Negate specific IMU columns ---\n",
    "#         negate_cols = ['acc_x', 'rot_y', 'rot_z']\n",
    "#         df_seq[negate_cols] *= -1\n",
    "    \n",
    "#     linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n",
    "#     df_seq['linear_acc_x'], df_seq['linear_acc_y'], df_seq['linear_acc_z'] = linear_accel[:, 0], linear_accel[:, 1], linear_accel[:, 2]\n",
    "#     angular_vel = calculate_angular_velocity_from_quat(df_seq)\n",
    "#     df_seq['angular_vel_x'], df_seq['angular_vel_y'], df_seq['angular_vel_z'] = angular_vel[:, 0], angular_vel[:, 1], angular_vel[:, 2]\n",
    "#     df_seq['angular_distance'] = calculate_angular_distance(df_seq)\n",
    "\n",
    "\n",
    "#     for i in range(1, 6):\n",
    "#         pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]; tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n",
    "#         df_seq[f'tof_{i}_mean'], df_seq[f'tof_{i}_std'], df_seq[f'tof_{i}_min'], df_seq[f'tof_{i}_max'] = tof_data.mean(axis=1), tof_data.std(axis=1), tof_data.min(axis=1), tof_data.max(axis=1)\n",
    "\n",
    "#     mat_unscaled = df_seq[feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n",
    "#     mat = scaler.transform(mat_unscaled)\n",
    "#     pad = pad_sequences_torch([mat], maxlen=pad_len, padding='pre', truncating='pre')\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         x = torch.FloatTensor(pad).to(device)\n",
    "#         outputs = None\n",
    "#         for model in models:\n",
    "#             model.eval()\n",
    "#             logits = model(x)[0]\n",
    "#             p = torch.softmax(logits, dim=1)\n",
    "#             if outputs is None: outputs = p\n",
    "#             else: outputs += p\n",
    "#         outputs /= len(models)\n",
    "        \n",
    "#         idx = int(outputs.argmax(dim=1)[0].cpu().numpy())\n",
    "\n",
    "#     composite_class = str(gesture_classes[idx])\n",
    "#     final_class = composite_class.split('_')[1]\n",
    "    \n",
    "#     return final_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60999278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T11:42:49.694233Z",
     "iopub.status.busy": "2025-09-03T11:42:49.693875Z",
     "iopub.status.idle": "2025-09-03T11:42:49.706658Z",
     "shell.execute_reply": "2025-09-03T11:42:49.706121Z"
    },
    "papermill": {
     "duration": 0.017247,
     "end_time": "2025-09-03T11:42:49.707613",
     "exception": false,
     "start_time": "2025-09-03T11:42:49.690366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SUBJECT_HISTORY = {}\n",
    "\n",
    "# FINAL_PREDICTIONS: 存储经过最优分配后，每个序列最终确定的标签\n",
    "FINAL_PREDICTIONS = {}\n",
    "gesture_classes = None\n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    一个实现了“全局最优分配”后处理的、有状态的预测函数。\n",
    "    \"\"\"\n",
    "    global gesture_classes, SUBJECT_HISTORY, FINAL_PREDICTIONS\n",
    "\n",
    "    # --- 初始化/重置逻辑 ---\n",
    "    # 通过检查 gesture_classes 是否已加载，来判断是否是新一轮提交的开始\n",
    "    if gesture_classes is None:\n",
    "        print(\"First call of this submission run. Initializing...\")\n",
    "        gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "        # 清空上一轮的记忆\n",
    "        SUBJECT_HISTORY = {}\n",
    "        FINAL_PREDICTIONS = {}\n",
    "\n",
    "    # --- 1. 特征工程 (与您原来基本相同) ---\n",
    "    df_seq = sequence.to_pandas()\n",
    "    subject_id = df_seq['subject'].iloc[0]\n",
    "    sequence_id = df_seq['sequence_id'].iloc[0]\n",
    "    \n",
    "    df_demo = demographics.to_pandas()\n",
    "    df_seq = df_seq.merge(df_demo[['subject', 'handedness']], on='subject', how='left')\n",
    "    \n",
    "    handedness = df_seq['handedness'].iloc[0]\n",
    "    if handedness == 0:\n",
    "        # --- a) Swap sensor 3 and sensor 5 data ---\n",
    "        \n",
    "        # Find all columns related to thermopile and time-of-flight sensors 3 and 5\n",
    "        cols_3 = [c for c in df_seq.columns if any(p in c for p in ['tof_3', 'thm_3'])]\n",
    "        cols_5 = [c for c in df_seq.columns if any(p in c for p in ['tof_5', 'thm_5'])]\n",
    "        \n",
    "        # Sort to ensure a one-to-one mapping for the swap\n",
    "        cols_3.sort()\n",
    "        cols_5.sort()\n",
    "        \n",
    "        # Sanity check\n",
    "        if len(cols_3) == len(cols_5):\n",
    "            # Perform the swap using a temporary variable\n",
    "            temp_cols_3_data = df_seq[cols_3].copy()\n",
    "            df_seq[cols_3] = df_seq[cols_5]\n",
    "            df_seq[cols_5] = temp_cols_3_data\n",
    "        \n",
    "        # --- b) Negate specific IMU columns ---\n",
    "        negate_cols = ['acc_x', 'rot_y', 'rot_z']\n",
    "        df_seq[negate_cols] *= -1\n",
    "    \n",
    "    linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n",
    "    df_seq['linear_acc_x'], df_seq['linear_acc_y'], df_seq['linear_acc_z'] = linear_accel[:, 0], linear_accel[:, 1], linear_accel[:, 2]\n",
    "    angular_vel = calculate_angular_velocity_from_quat(df_seq)\n",
    "    df_seq['angular_vel_x'], df_seq['angular_vel_y'], df_seq['angular_vel_z'] = angular_vel[:, 0], angular_vel[:, 1], angular_vel[:, 2]\n",
    "    df_seq['angular_distance'] = calculate_angular_distance(df_seq)\n",
    "\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]; tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n",
    "        df_seq[f'tof_{i}_mean'], df_seq[f'tof_{i}_std'], df_seq[f'tof_{i}_min'], df_seq[f'tof_{i}_max'] = tof_data.mean(axis=1), tof_data.std(axis=1), tof_data.min(axis=1), tof_data.max(axis=1)\n",
    "\n",
    "    mat_unscaled = df_seq[feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n",
    "    mat = scaler.transform(mat_unscaled)\n",
    "    pad = pad_sequences_torch([mat], maxlen=pad_len, padding='pre', truncating='pre')\n",
    "    \n",
    "    # --- 2. 模型预测 -> 获取Log-Softmax概率 ---\n",
    "    with torch.no_grad():\n",
    "        x = torch.FloatTensor(pad).to(device)\n",
    "        all_logits = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            # 假设您的模型现在输出 (B, 102) 的logits\n",
    "            logits = model(x)[0] \n",
    "            all_logits.append(logits)\n",
    "        \n",
    "        # 集成logits并计算log-softmax\n",
    "        avg_logits = torch.stack(all_logits).mean(dim=0)\n",
    "        log_probs = F.log_softmax(avg_logits, dim=1).cpu().numpy().flatten() # (102,)\n",
    "\n",
    "    # --- 3. 存储当前序列的预测历史 ---\n",
    "    if subject_id not in SUBJECT_HISTORY:\n",
    "        SUBJECT_HISTORY[subject_id] = []\n",
    "        \n",
    "    # 存储唯一的序列ID和对应的log概率\n",
    "    # (需要处理同一个序列被重复预测的情况, 如果API可能这样做)\n",
    "    if not any(d['seq_id'] == sequence_id for d in SUBJECT_HISTORY[subject_id]):\n",
    "        SUBJECT_HISTORY[subject_id].append({'seq_id': sequence_id, 'log_probs': log_probs})\n",
    "\n",
    "    # --- 4. 核心：为当前被试的所有已知序列，重新进行全局最优分配 ---\n",
    "    subject_history = SUBJECT_HISTORY[subject_id]\n",
    "    num_sequences_so_far = len(subject_history)\n",
    "    num_labels = len(log_probs) # 102\n",
    "\n",
    "    # a) 构建成本矩阵\n",
    "    # 形状: (N个序列, 102个标签)\n",
    "    # 值: 负的log概率 (因为算法求的是最小成本，等价于求最大log概率和)\n",
    "    cost_matrix = np.zeros((num_sequences_so_far, num_labels))\n",
    "    for i in range(num_sequences_so_far):\n",
    "        cost_matrix[i, :] = -subject_history[i]['log_probs']\n",
    "\n",
    "    # b) 使用匈牙利算法求解最优分配\n",
    "    # row_ind是序列索引, col_ind是分配给该序列的最佳标签索引\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "    # c) 更新所有序列的最终预测结果\n",
    "    for i in range(num_sequences_so_far):\n",
    "        seq_info = subject_history[i]\n",
    "        assigned_label_index = col_ind[i]\n",
    "        final_gesture_name = gesture_classes[assigned_label_index] # 假设gesture_classes现在是102个复合标签\n",
    "\n",
    "        # 将最终确定的预测结果存入“最终答案”字典\n",
    "        final_gesture_name = final_gesture_name.split('_')[1]\n",
    "        FINAL_PREDICTIONS[seq_info['seq_id']] = final_gesture_name\n",
    "        \n",
    "    # --- 5. 返回当前序列的最终预测结果 ---\n",
    "    return FINAL_PREDICTIONS[sequence_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee43d6e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T11:42:49.713421Z",
     "iopub.status.busy": "2025-09-03T11:42:49.713233Z",
     "iopub.status.idle": "2025-09-03T11:42:52.106149Z",
     "shell.execute_reply": "2025-09-03T11:42:52.105520Z"
    },
    "papermill": {
     "duration": 2.397354,
     "end_time": "2025-09-03T11:42:52.107471",
     "exception": false,
     "start_time": "2025-09-03T11:42:49.710117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call of this submission run. Initializing...\n"
     ]
    }
   ],
   "source": [
    "# Kaggle competition interface\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd1c9c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T11:42:52.113953Z",
     "iopub.status.busy": "2025-09-03T11:42:52.113431Z",
     "iopub.status.idle": "2025-09-03T11:42:52.212570Z",
     "shell.execute_reply": "2025-09-03T11:42:52.212003Z"
    },
    "papermill": {
     "duration": 0.103312,
     "end_time": "2025-09-03T11:42:52.213658",
     "exception": false,
     "start_time": "2025-09-03T11:42:52.110346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>gesture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>Forehead - pull hairline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>Eyelash - pull hair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id                   gesture\n",
       "0  SEQ_000001  Forehead - pull hairline\n",
       "1  SEQ_000011       Eyelash - pull hair"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"/kaggle/working/submission.parquet\").head(5)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7863210,
     "sourceId": 12859936,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8140529,
     "sourceId": 12923195,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7900929,
     "sourceId": 12936219,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8195289,
     "sourceId": 12949944,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25.302226,
   "end_time": "2025-09-03T11:42:54.638800",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-03T11:42:29.336574",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
